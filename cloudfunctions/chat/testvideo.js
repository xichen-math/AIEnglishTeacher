console.log('==== è„šæœ¬å¼€å§‹æ‰§è¡Œ ====');

const fs = require('fs');
const sdk = require('microsoft-cognitiveservices-speech-sdk');
const path = require('path');
const ffmpeg = require('fluent-ffmpeg');

console.log('==== æ¨¡å—åŠ è½½å®Œæˆ ====');

// æŒ‡å®š ffmpeg è·¯å¾„ï¼ˆå¦‚æœéœ€è¦ï¼‰
// å¦‚æœä½ çŸ¥é“ ffmpeg çš„ç¡®åˆ‡å®‰è£…è·¯å¾„ï¼Œå¯ä»¥å–æ¶ˆä¸‹é¢è¿™è¡Œçš„æ³¨é‡Šå¹¶ä¿®æ”¹ä¸ºæ­£ç¡®è·¯å¾„
// ffmpeg.setFfmpegPath('C:\\ffmpeg\\bin\\ffmpeg.exe');

/**
 * ä½¿ç”¨ ffmpeg å°†éŸ³é¢‘æ–‡ä»¶è½¬æ¢ä¸º WAV æ ¼å¼
 * @param {string} inputPath è¾“å…¥éŸ³é¢‘æ–‡ä»¶è·¯å¾„
 * @param {string} outputPath è¾“å‡º WAV æ–‡ä»¶è·¯å¾„
 * @returns {Promise<void>}
 */
function convertToWav(inputPath, outputPath) {
  return new Promise((resolve, reject) => {
    ffmpeg(inputPath)
      .toFormat('wav')
      .audioFrequency(16000)
      .audioChannels(1)
      .on('end', () => {
        console.log(`è½¬æ¢å®Œæˆï¼Œæ–‡ä»¶å·²ä¿å­˜ä¸º: ${outputPath}`);
        resolve();
      })
      .on('error', (err) => {
        console.error('è½¬æ¢è¿‡ç¨‹ä¸­å‡ºé”™:', err);
        reject(err);
      })
      .save(outputPath);
  });
}

/**
 * ä½¿ç”¨ Azure è¯­éŸ³æœåŠ¡è¯†åˆ«æœ¬åœ° WAV éŸ³é¢‘
 */
async function recognizeWavFile(wavPath) {
  return new Promise(async (resolve, reject) => {
    try {
      if (!fs.existsSync(wavPath)) {
        return reject(new Error(`æ‰¾ä¸åˆ°æ–‡ä»¶: ${wavPath}`));
      }

      // å…ˆè½¬æ¢ä¸ºæ ‡å‡† WAV æ ¼å¼
      const outputWavPath = path.join(path.dirname(wavPath), `converted_${path.basename(wavPath)}`);
      await convertToWav(wavPath, outputWavPath);
      console.log('æ–‡ä»¶å‡†å¤‡å°±ç»ªï¼Œå¼€å§‹è¯†åˆ«');

      const speechKey = process.env.AZURE_SPEECH_KEY || 'bd5f339e632b4544a1c9a300f80c1b0a';
      const speechRegion = process.env.AZURE_SPEECH_REGION || 'eastus';

      if (!speechKey) {
        return reject(new Error('ç¼ºå°‘ Azure Speech Key'));
      }

      const speechConfig = sdk.SpeechConfig.fromSubscription(speechKey, speechRegion);
      speechConfig.speechRecognitionLanguage = 'en-US';

      const audioConfig = sdk.AudioConfig.fromWavFileInput(fs.readFileSync(outputWavPath));
      const recognizer = new sdk.SpeechRecognizer(speechConfig, audioConfig);

      recognizer.recognizeOnceAsync(result => {
        recognizer.close();
        if (result.reason === sdk.ResultReason.RecognizedSpeech) {
          resolve(result.text);
        } else if (result.reason === sdk.ResultReason.NoMatch) {
          reject(new Error('æ— æ³•è¯†åˆ«è¯­éŸ³'));
        } else if (result.reason === sdk.ResultReason.Canceled) {
          const cancellation = sdk.CancellationDetails.fromResult(result);
          reject(new Error(`è¯†åˆ«å–æ¶ˆï¼š${cancellation.reason} - ${cancellation.errorDetails}`));
        }
      }, error => {
        recognizer.close();
        reject(error);
      });
    } catch (err) {
      reject(err);
    }
  });
}

// ğŸ§ª æœ¬åœ°æµ‹è¯•
if (require.main === module) {
  try {
    console.log('==== å¼€å§‹æµ‹è¯•éŸ³é¢‘è¯†åˆ« ====');
    const filePath = path.join(__dirname, 'test1.wav'); 
    console.log(`==== éŸ³é¢‘æ–‡ä»¶è·¯å¾„: ${filePath} ====`);
    
    recognizeWavFile(filePath)
      .then(text => console.log('âœ… è¯†åˆ«ç»“æœ:', text))
      .catch(err => {
        console.error('âŒ æ•è·åˆ°çš„é”™è¯¯:', err);
      });
  } catch (globalError) {
    console.error('ğŸ”´ å…¨å±€é”™è¯¯:', globalError);
  }
}

module.exports = { recognizeWavFile, convertToWav };
